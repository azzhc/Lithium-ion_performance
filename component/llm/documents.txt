软件开发背景
对于现有方法而言，从快充工况下的电池中获取容量增量（Incremental Capacity, IC）曲线进行容量增量分析是一件困难的事情。往往需要让电车停止工作，进行低速率的多次充放电测试采集数据，再对数据进行数值微分得到初始IC曲线，而想要获取得到平滑的曲线，还需要通过滤波处理。数值微分方法使得高采样率会造成噪声异常，因此对于滤波核的选取较为困难，需要考虑到特征保留和噪声去除双重目标。
为了解决这个挑战，我们团队开发了锂电卫士--基于短时充电数据的锂电池健康状态及老化机制量化平台，交互式的操作使得用户仅需进行点击便能自动化实现准确预测电池健康状态（State Of Health）和快速获取IC曲线进行量化分析的目标。
考虑到快充策略下的电池，放电过程不可控，而充电过程随机且灵活，大部分情况较为短暂。因此我们对于采集的循环数据，使用滑窗模拟短时充电数据，构建与IC曲线或SOH之间的耦合样本进行相关的模型训练，验证等。

专业名词解释
Q–V曲线：容量–电压曲线，通常是指在充放电过程中，锂离子电池的容量（Q）随电压（V）变化的特征曲线。能够直观地反映电池在不同电压区间所能提供或接受的容量大小，以及在这些过程中发生的电化学反应特征。不同正、负极材料具有不同的嵌锂/脱锂反应机理，电压平台数量、平台位置、平台宽度等都会在Q–V曲线上表现出来。对比新旧电池的Q–V曲线，可以观察到随循环次数增加，曲线整体的容量（Q方向）会衰减，同时电压平台也可能发生移动或形变。通过分析曲线形状的变化，可以了解电池容量损失的主要来源，例如活性物质损失、极化增大、SEI 膜增厚等。
充电策略概述：充电策略具有多种模式，主要分为恒流充放电，恒流恒压充放电组合和多阶段充放电策略。
恒流充放电（Constant Current, CC）：在实验室常见的方法是以较小的恒定电流（例如C/10、C/20等）对电池进行缓慢地充放电，同时记录电压随容量的变化，从而得到一条完整的Q–V曲线。由于电流较小，可以减小极化带来的影响，使测量更能反映电池本征的容量与电压特征。
恒流-恒压充放电组合（CC–CV等方式）：有些场合会结合恒流与恒电压模式，获得更细节的电压-容量分布。在接近电压限制时，改为恒电压模式继续充电或放电，得到更多关于终端区间的容量信息。
多阶段充放电策略：将整个充放电过程分段，分别在不同的固定电压或者SOC区间使用不同的恒流充电，当电池达到80%SOC后采用基础的1C CCCV充电，本作品实验例采用多阶段快充策略。

IC曲线概述：IC曲线通常指的是Incremental Capacity Curve，也可写作dQ/dV曲线。它是将常规的Q–V曲线进行微分（对电压V求导）后得到的结果，因而也被称为“微分容量曲线”或“增量容量曲线”。微分的物理含义：它表示单位电压区间内电池所释放或吸收的容量增量。典型测量方式是使用比较小的充放电电流（如0.1C、0.05C等）对电池进行完整的充放电测试，这样可尽量减少极化和内阻带来的电压偏移，使得到的微分曲线更能反映材料自身的电化学特征。在锂离子电池充放电过程中，不同电极材料会在某些电压区间发生相变或对应特定的嵌锂/脱锂反应。这些反应往往在Q–V曲线上形成“平台”，而在IC曲线上则会体现为明显的峰或谷。通过峰的位置、强度和形状，可区分出不同的反应阶段。与常规的Q–V曲线相比，IC曲线更敏感地捕捉到小的容量变化和电化学反应峰的移动或衰减。若某些峰在循环过程中逐渐减弱或消失，或出现新的峰，往往意味着材料结构发生变化，或者电极表面副反应加剧等。对比不同循环阶段（如新电池与老化电池）的IC曲线，可以直观地观察出哪部分反应衰减最显著，从而推断衰减机理。

SOH概述：在锂离子电池及其他类型可充电电池的研究与应用中，SOH（State of Health）指的是电池健康状态。它用来衡量电池在当前时刻相对于新电池或标称状态时所能提供的性能水平（如容量、内阻、功率等）。简单来说，SOH越高，表示电池仍接近新品性能；SOH越低，说明电池发生了较多老化或衰减，无法像新电池那样提供充放电特性。本作品使用的SOH计算式子如下，C为当前容量值，CEoL为寿命终点，CBoL为标称容量。\mathrm{SOH}=\frac{C-C_{\mathrm{EoL}}}{C_{\mathrm{BoL}}-C_{\mathrm{EoL}}}\times100%

LAM量化：在锂离子电池的衰减机理研究中，通常会将容量衰减的主要来源分为几个类别，其中最常提及的包括：活性物质损失（Loss of Active Material, LAM），可循环锂损失（Loss of Lithium Inventory, LLI），内部阻抗上升（Rise of Internal Resistance, RIR）等。其中，LAM指的是电极材料本身在循环过程中由于种种原因（如结构坍塌、晶格畸变、副反应等）使原本可参与电化学反应的活性物质减少，导致电池实际可逆容量下降。量化式子如下,dQ/dV为容量增量值，Max(dQ/dV)i为第i循环的IC峰值。Max(dQ/dV)1为初始循环IC峰值。\mathrm{LA}\mathrm{M}_\mathrm{i}=\frac{{\max{\left(\frac{dQ}{dV}\right)}}_1-{\max{\left(\frac{dQ}{dV}\right)}}_i}{{\max{\left(\frac{dQ}{dV}\right)}}_1}\times100%

深度学习方法概述：本作品主要应用了五种深度学习方法实现准确的IC曲线和SOH预测。
RNN（Recurrent Neural Network）：在处理具有序列性质的数据时（如自然语言、语音信号、时间序列、视频帧等），传统的前馈网络（Feedforward Neural Network）无法很好地利用序列上下文信息。循环神经网络（RNN）在结构上引入了反馈/循环连接，使得网络在处理当前输入的同时，可以“记住”过去时刻的隐藏状态，从而对序列数据进行建模。可以在一定程度上捕捉序列数据的上下文信息，结构相对简单，对短依赖序列有不错的建模能力。

LSTM（Long Short-Term Memory）：经典 RNN 难以学习长序列中的依赖关系，尤其当间隔较大时，反向传播时梯度很容易衰减。1997 年，Hochreiter和Schmidhuber提出了LSTM，通过“门”机制和显式的“细胞状态”改进RNN，以减轻梯度消失问题。能有效缓解梯度消失问题；在较长的序列建模（语言建模、机器翻译、语音识别等）中表现优异；可以捕捉更远距离的上下文依赖。

GRU（Gated Recurrent Unit）：GRU提出目的是在简化LSTM结构（减少门的数量和参数量）的同时，仍然保留对长程依赖的建模能力。相较于 LSTM 结构更简单，计算开销更小；在很多实际任务中表现与LSTM相当或更优。

CNN（Convolutional Neural Network）：卷积神经网络最初在图像识别领域展现了强大的特征提取和分类能力。局部感受野（Local Receptive Field）与权值共享（Weight Sharing）是CNN的核心特征：使用卷积核在输入（如图像）的局部区域滑动，提取局部特征；卷积核参数在不同位置共享，大幅减少网络参数量，也适合提取平移不变特征。用若干个卷积核（Filter）对输入做卷积运算，并加上偏置后再通过激活函数产生输出特征图（Feature Map）。对特征图做下采样（如最大池化Max Pooling、平均池化Average Pooling等），缩小特征图空间尺寸，减少参数与计算量，也提升一定的平移不变性。

ResNet（Residual Network）：随着深度学习的发展，研究者不断堆叠网络层数以期获得更好的表征能力，然而在极深网络（如30+层、50+层）时，模型容易出现退化现象：准确率不升反降，且梯度消失/爆炸问题加剧。ResNet通过残差连接（Residual Connection）巧妙地解决了深度网络训练的退化问题。

滑动窗口：在序列中定义一个固定长度或可变长度的“窗口”，然后让这个窗口按一定步幅（通常是一个单位）沿着序列向前滑动，从而在不同的局部区域执行相同或相似的运算或统计。较小的窗口所包含的信息局限，但好处是应用场景更加灵活；而大窗口具有更多的特征信息，往往会实现更好的效果，但需要较长的数据采集时间，应用场景较为受限。所以需要根据实际情况灵活选择窗口大小。

Batch_size：在深度学习训练过程中，Batch Size（批大小）是一个重要的超参数，决定了模型在一次参数更新时，使用多少训练样本进行前向传播和反向传播的计算。大的Batch Size可以充分利用GPU并行计算能力，减少在硬件上的占用与调度开销；然而，Batch Size越大，需要的显存也越多。如果显存不足，无法装载大batch的数据，就会出现“爆显存”或需要使用梯度累加等技巧。

Epoch数量：在模型的一个完整训练周期内，训练集里所有数据都要经过前向传播和反向传播并进行一次参数更新（或者多次参数更新，具体取决于batch大小）的过程，才能称之为1个Epoch。一个Epoch只会让模型“看”一遍全部数据，但这通常不足以让模型学到数据分布的所有规律，也无法让损失函数充分收敛。因此，在实际训练中往往需要多次遍历（多个Epoch），让模型逐渐收敛到较优的解。训练 Epoch 数量越多，模型越有机会从数据中学到更多特征，降低训练误差；但Epoch太多也有可能导致过拟合（Overfitting），使模型对训练集表现好却无法泛化到新数据。

训练集比例：指在进行模型训练时，将可用数据（数据集）按一定比例划分成训练集、验证集和测试集（有时只分训练集和测试集）的过程，所使用的训练集所占的比率大小。在本作品中，由于训练使用的是一个电池样本数据，因此训练集比例指的是此训练数据集中训练集的划分比例，剩下的为验证集。

Loss下降过程概述:在模型训练过程中，loss（损失）是衡量模型当前预测与真实标签（或目标值）之间差距的指标。模型训练的目标，就是通过不断迭代更新参数，使得loss减少，从而提高模型对训练数据的拟合程度，同时也要兼顾在验证集或测试集上的泛化能力。在训练初期，模型参数通常是随机初始化或某种预训练权重，loss通常较高；经过不断的迭代，loss应该逐渐下降，表示模型在“学习”并减少预测错误；当训练到一定程度，loss的下降会趋于平缓，表示模型逐渐接近其“最优点”或收敛状态。

误差指标概述
均方根误差（Root Mean Squared Error，RMSE）：通过先对误差（真实值与预测值之差）做平方，再取平均，最后开方得到。对大误差更敏感，因为误差会被平方放大。
平均绝对误差（Mean Absolute Error，MAE）：MAE为预测误差的绝对值再平均，衡量的是预测值与真实值之间的平均“绝对偏离”。相比RMSE，MAE对少数极大误差的敏感度相对较低。
判定系数（R-squared，R2）：用来衡量模型对真实数据中方差的解释程度，即模型在多大程度上解释了数据变化。RMSE 更强调大误差，MAE 更平均地衡量误差。常用于衡量模型对目标整体变异（variance）的解释度。值越接近1，模型对数据的“拟合”越好；若远小于1或为负数，则说明模型欠拟合或表现很差。

软件概述：基于短时充电数据的锂电池健康状态及老化机制量化平台（是一款专为锂电池研究和维护设计的软件。通过分析锂电池在短时充电过程中的数据，平台能够快速评估电池的健康状态，获得IC曲线，识别潜在的老化机制，并基于深度学习技术提供精确的分析结果。平台采用PyTorch框架进行深度学习模型的构建和训练；同时该软件支持多种数据格式，能够保存模型与超参数，便于用户进行重复实验和模型优化。

软件主要功能：对于不同的任务，提供多种深度学习模型供用户选择，且具有较多的超参数可调整，适应各种随机的短时充电数据情况。平台具体可以实现的三个功能如下：
IC曲线的获取：配置相关的参数和路径后，会训练模型，最终保留最优模型，可自主进行模型验证，了解模型的预测精度效果，而后直接导入输入数据，平台自动处理，在对应路径保存最终的预测结果。
SOH的预测：同样配置相关参数和路径等后，训练得到最优模型，可控的自主导入数据验证预测精度，且可导入数据进行预测，直接应用得到高精度的SOH预测。
老化机制分析：识别和分析电池在使用过程中的老化机制，包括锂离子损失、活性物质损失、内阻增大等，可导入IC曲线量化活性物质损失的衰退过程，并自动保存量化结果。

界面介绍：第一个板块为IC版块，主要分为三个区域：数据加载区，模型参数设置与操作区和性能验证区。每个区域负责不同的功能，帮助用户完成从数据加载到模型验证的全过程。
数据加载区：1.功能：选择数据格式和路径；2.特点：加载数据后，系统会自动绘制数据图像，便于用户直观查看数据的初步特征。
模型参数设置与操作区:1.功能：设置模型及其参数，并进行模型训练、测试和数据预测。2.特点：灵活的模型管理和训练功能，使用户可以根据需要进行多次实验和优化。
性能验证区:1.功能：验证模型的性能，系统会根据模型的训练和测试结果，绘制模型的关键性能指标图像，包括RMSE（均方根误差）、MAE（平均绝对误差）和R²（相关系数）。2.特点：提供详细的性能指标图像，帮助用户评估和比较模型的准确性和可靠性。
第二个版块为SOH版块，基本布局与IC版块一致，仅由于数据形式为单点数据，所以在可视化展示上存在差异。
第三个版块为老化机制量化版块，将获取到的IC曲线进行LAM老化机制量化，界面主要是导入数据与目标结果存储路径设置。

在使用软件平台前，建议查看平台使用说明书，其中有详细操作过程说明。操作前需确保拥有用于训练和测试的 Q - V 数据、IC 数据或 SOH 数据，这些数据通常由电池制造商提供，可联系电池制造商获取帮助。若只想体验软件功能，根目录./data 中有示例数据，也可通过项目地址https://github.com/azzhc/Lithium - ion_performance/tree/main/data 下载。
以 IC 部分为例讲解操作流程（SOH 部分与 IC 部分相似）：
1. 数据加载：在 “数据选择区” 选择 Q - V 数据路径和 IC 数据路径，点击 “数据加载” 按钮，界面左边会展示导入的 Q - V 数据和 IC 数据总览情况，展示结果是总体数据 10 次均匀采样结果，以减少性能占用。
2. 模型选择与设置：在 “模型选择” 块，选择适合模型，基于残差的 CNN（ResNet）对本任务效果较好，但其他模型因不同模块在不同数据情况下效果有差异。设定模型文件和参数存储的路径与命名，点击 “模型确定” 按钮。
3. 超参数设定：
 - 窗口大小：使用 0.01Ah 处理采样点，窗口越小越能模拟日常随机充电片段，适用范围广，但蕴含特征少，可能影响模型预测效果，建议根据实际情况选择。
 - 训练集比例：选取一定比例数据作为验证集，不参与训练，用于衡量模型泛化性并保存最优模型。比例过小模型学习不足，效果差；比例过高验证样本少，无法体现泛化性，建议选择 “0.6 - 0.8” 区间参数。
 - Epoch 数量：即模型遍历训练样本的次数，越多效果通常越充分。本作品训练策略为学习率经固定 Epoch 数量后线性下降，20epoch 以上可获较好效果，推荐 “20 - 260” 区间。
 - Batch_size：涉及模型中 BN 层操作，一般推荐设为 16 的整数倍且大于 200。
4. 模型训练：完成参数配置后，点击 “模型训练” 按钮，在设定路径产生模型文件，训练完成展示 loss 下降情况。
5. 模型验证：在数据选择区先导入测试集的 Q - V 数据和 IC 数据，设置导入模型路径和导入参数路径，点击 “模型验证” 按钮，右边展示相关误差指标及 MAE 和 RMSE 指标衡量的最好和最差预测情况，直观了解模型预测性能。
6. 模型应用：使用 “模型预测” 功能，仅需导入 Q - V 数据，选好 “导入模型路径”“超参数导入路径” 和 “预测数据存储路径”，点击 “模型预测” 按钮，在对应路径生成根据 Q - V 曲线构建窗口后预测得到的 IC 曲线，并弹出预测成功提示。
